{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMK5rDevirV3oZz4tRH6V/X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeraaaaWei/data_analytics/blob/Python/Fund%20Data%20Crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UODn7dOoCtnG"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import datetime\n",
        "import re\n",
        "import numpy as np\n",
        "import json\n",
        "from six import StringIO\n",
        "from six import BytesIO\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td9riV7lDUyj"
      },
      "source": [
        "##获取代理池，详见 https://github.com/1again/SmartProxyPool\n",
        "def get_proxy():\n",
        "    data_json = requests.get(\"http://proxy.1again.cc:35050/api/v1/proxy/?region=中国\").text\n",
        "    data = json.loads(data_json)\n",
        "    return data['data']['proxy']\n",
        "\n",
        "\n",
        "def get_url(url, params=None, proxies=None,header=None):\n",
        "    rsp = requests.get(url, params=params, proxies={\"http\": proxies},headers=header)    \n",
        "    rsp.raise_for_status()\n",
        "    return rsp.text\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uYNqqBkDifs"
      },
      "source": [
        "##获取全基金\n",
        "url = 'http://fund.eastmoney.com/js/fundcode_search.js'\n",
        "html = get_url(url,proxies=None)\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "exec('securities'+str(soup).strip('var '))\n",
        "funds = pd.DataFrame(data=securities, index=None, columns=['code','2','name','type','5'])\n",
        "# fund type类型 股票型-  混合型 债券型 指数型 保本型 理财型 货币型 混合-FOF ...\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxhvTXL3D6XJ"
      },
      "source": [
        "def get_header():\n",
        " # user_agent列表\n",
        "    user_agent_list = [\n",
        "  'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.71 Safari/537.1 LBBROWSER',\n",
        "  'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)',\n",
        "  'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.84 Safari/535.11 SE 2.X MetaSr 1.0',\n",
        "  'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Maxthon/4.4.3.4000 Chrome/30.0.1599.101 Safari/537.36',\n",
        "  'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 UBrowser/4.0.3214.0 Safari/537.36'\n",
        "    ]\n",
        "# referer列表\n",
        "    referer_list = [\n",
        "  'http://fund.eastmoney.com/110022.html',\n",
        "  'http://fund.eastmoney.com/110023.html',\n",
        "  'http://fund.eastmoney.com/110024.html',\n",
        "  'http://fund.eastmoney.com/110025.html',\n",
        "  'https://www.baidu.com/s?wd=%E5%A4%A9%E5%A4%A9%E5%9F%BA%E9%87%91%E7%BD%91'\n",
        "    ]\n",
        "# 获取一个随机user_agent和Referer\n",
        "    header = {'User-Agent': random.choice(user_agent_list),'Referer': random.choice(referer_list)}\n",
        "    return header\n",
        "\n",
        "\n",
        "def get_fund_data(code, start='', end='',proxy_list=0):\n",
        "    url = 'http://fund.eastmoney.com/f10/F10DataApi.aspx'\n",
        "    params = {'type': 'lsjz', 'code': code, 'page': 1, 'per': 40, 'sdate': start, 'edate': end}\n",
        "    if proxy_list==0:\n",
        "        html = get_url(url,params,proxies=None,header=get_header())\n",
        "    else:\n",
        "        while(1):\n",
        "            try:\n",
        "                proxy_random=random.choice(proxy_list)\n",
        "                html = get_url(url,params,proxies=proxy_random,header=get_header())\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    records = pd.DataFrame(data=None, index=None, columns=['Code','NetAssetValue','AccumulatedNetValue','ChangePercent'])\n",
        "    tab = soup.findAll('tbody')[0]\n",
        "    for tr in tab.findAll('tr'):\n",
        "        if tr.findAll('td') and len((tr.findAll('td'))) == 7:\n",
        "            date=datetime.datetime.strptime(str(tr.select('td:nth-of-type(1)')[0].getText().strip()),'%Y-%m-%d')\n",
        "            if tr.select('td:nth-of-type(2)')[0].getText().strip()=='':\n",
        "                nav=0\n",
        "            else:\n",
        "                nav=float(tr.select('td:nth-of-type(2)')[0].getText().strip())\n",
        "\n",
        "            if tr.select('td:nth-of-type(3)')[0].getText().strip()=='':\n",
        "                aav=0\n",
        "            else:\n",
        "                aav=float(tr.select('td:nth-of-type(3)')[0].getText().strip()) \n",
        "\n",
        "            if tr.select('td:nth-of-type(4)')[0].getText().strip('%')=='':\n",
        "                cpt=0\n",
        "            else:\n",
        "                cpt=float(tr.select('td:nth-of-type(4)')[0].getText().strip('%'))\n",
        "            records.loc[date,:]=[code,nav,aav,cpt]\n",
        "            \n",
        "    reg=re.compile(r\"(?<=pages:)\\d+\")\n",
        "    match=reg.search(str(soup))\n",
        "    pages=int(match.group(0))\n",
        "    if pages >1:\n",
        "        for p in range (2,pages+1):\n",
        "            params = {'type': 'lsjz', 'code': code, 'page': p, 'per': 40, 'sdate': start, 'edate': end}\n",
        "            html = get_url(url, params)\n",
        "            soup = BeautifulSoup(html, 'html.parser')\n",
        "            tab = soup.findAll('tbody')[0]\n",
        "            for tr in tab.findAll('tr'):\n",
        "                if tr.findAll('td') and len((tr.findAll('td'))) == 7:\n",
        "                    date=datetime.datetime.strptime(str(tr.select('td:nth-of-type(1)')[0].getText().strip()),'%Y-%m-%d')\n",
        "                    if tr.select('td:nth-of-type(2)')[0].getText().strip()=='':\n",
        "                        nav=0\n",
        "                    else:\n",
        "                        nav=float(tr.select('td:nth-of-type(2)')[0].getText().strip())\n",
        "                    \n",
        "                    if tr.select('td:nth-of-type(3)')[0].getText().strip()=='':\n",
        "                        aav=0\n",
        "                    else:\n",
        "                        aav=float(tr.select('td:nth-of-type(3)')[0].getText().strip()) \n",
        "                    \n",
        "                    if tr.select('td:nth-of-type(4)')[0].getText().strip('%')=='':\n",
        "                        cpt=0\n",
        "                    else:\n",
        "                        cpt=float(tr.select('td:nth-of-type(4)')[0].getText().strip('%'))\n",
        "                        \n",
        "                    records.loc[date,:]=[code,nav,aav,cpt]    \n",
        "    return records\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 获取数据示例：get_fund_data('163402','2018-09-18','2019-09-18')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "eYMq6auDEvfC",
        "outputId": "da25344e-6044-4873-dc47-e8df1bdc15d7"
      },
      "source": [
        "get_fund_data('163402','2018-09-18','2019-09-18')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>NetAssetValue</th>\n",
              "      <th>AccumulatedNetValue</th>\n",
              "      <th>ChangePercent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-09-18</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.7928</td>\n",
              "      <td>9.659</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-17</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.7874</td>\n",
              "      <td>9.6374</td>\n",
              "      <td>-1.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-16</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.7969</td>\n",
              "      <td>9.6754</td>\n",
              "      <td>-0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-12</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.7981</td>\n",
              "      <td>9.6802</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-11</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.7911</td>\n",
              "      <td>9.6522</td>\n",
              "      <td>-0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-09-25</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.6421</td>\n",
              "      <td>9.0571</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-09-21</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.6453</td>\n",
              "      <td>9.0699</td>\n",
              "      <td>2.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-09-20</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>9.0188</td>\n",
              "      <td>-0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-09-19</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.6343</td>\n",
              "      <td>9.026</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-09-18</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.8069</td>\n",
              "      <td>8.988</td>\n",
              "      <td>1.29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>245 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Code NetAssetValue AccumulatedNetValue ChangePercent\n",
              "2019-09-18  163402        0.7928               9.659          0.69\n",
              "2019-09-17  163402        0.7874              9.6374         -1.19\n",
              "2019-09-16  163402        0.7969              9.6754         -0.15\n",
              "2019-09-12  163402        0.7981              9.6802          0.88\n",
              "2019-09-11  163402        0.7911              9.6522         -0.49\n",
              "...            ...           ...                 ...           ...\n",
              "2018-09-25  163402        0.6421              9.0571          -0.5\n",
              "2018-09-21  163402        0.6453              9.0699          2.02\n",
              "2018-09-20  163402        0.6325              9.0188         -0.28\n",
              "2018-09-19  163402        0.6343               9.026          1.18\n",
              "2018-09-18  163402        0.8069               8.988          1.29\n",
              "\n",
              "[245 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xUeFyXOGLuL",
        "outputId": "a57b3123-8027-4f9a-e309-1427fc410ad0"
      },
      "source": [
        "##研究时间段：\n",
        "##'2014-06-30'  '2015-06-01' 大涨\n",
        "##'2015-06-01'  '2016-03-10' 大跌\n",
        "##'2016-03-10'  '2018-01-18' 缓涨\n",
        "##'2018-01-18'  '2019-01-18' 缓跌\n",
        "##'2019-01-18'  '2020-01-18' 缓涨\n",
        "##'2020-01-18'  '2020-03-16' 疫情涨跌\n",
        "d1='2014-06-30'\n",
        "d2='2015-06-01'\n",
        "d3='2016-03-10'\n",
        "d4='2018-01-18'\n",
        "d5='2019-01-18' \n",
        "d6='2020-01-17'\n",
        "d7='2020-03-16'\n",
        "\n",
        "\n",
        "funds_list=list(funds[(funds['type']!='理财型') &(funds['type']!='货币型') & (funds['type']!='混合-FOF')]['code'])\n",
        "start_list=[]\n",
        "history_price= pd.DataFrame(data=None, index=None, columns=['code','p1','p2','p3','p4','p5','p6','p7'])\n",
        "total=len(funds_list)\n",
        "div=round(total/10)\n",
        "##手动配置代理列表，如采用后面的自动获取，需要注释掉\n",
        "proxy_list=['127.0.0.1:1080',None,]\n",
        "i=0\n",
        "for f in funds_list:\n",
        "    print('%4.2f %%\\r' %(float(i/total*100)),end=\"\") #显示百分比\n",
        "    history_price.loc[f,'code']=str(f)\n",
        "    history_price.loc[f,'p1']=get_fund_data(f,d1,d1,proxy_list)['AccumulatedNetValue'].values\n",
        "    history_price.loc[f,'p2']=get_fund_data(f,d2,d2,proxy_list)['AccumulatedNetValue'].values\n",
        "    history_price.loc[f,'p3']=get_fund_data(f,d3,d3,proxy_list)['AccumulatedNetValue'].values\n",
        "    history_price.loc[f,'p4']=get_fund_data(f,d4,d4,proxy_list)['AccumulatedNetValue'].values\n",
        "    history_price.loc[f,'p5']=get_fund_data(f,d5,d5,proxy_list)['AccumulatedNetValue'].values\n",
        "    history_price.loc[f,'p6']=get_fund_data(f,d6,d6,proxy_list)['AccumulatedNetValue'].values\n",
        "    history_price.loc[f,'p7']=get_fund_data(f,d7,d7,proxy_list)['AccumulatedNetValue'].values\n",
        "    i=i+1    \n",
        "\n",
        "##清洗数据\n",
        "washed_price=pd.DataFrame(data=None, index=history_price.index, columns=['code','p1','p2','p3','p4','p5','p6','p7'])\n",
        "washed_price['code']=history_price['code']\n",
        "for i in range(0,len(history_price)):\n",
        "    for j in range(1,8):\n",
        "        if np.size(history_price.iloc[i,j])==0:\n",
        "            washed_price.iloc[i,j]=0\n",
        "        else:\n",
        "            washed_price.iloc[i,j]=float(history_price.iloc[i,j])\n",
        "            \n",
        "washed_price=washed_price.drop(washed_price[washed_price['p7']==0].index)\n",
        "washed_price[washed_price[:]==0]=np.nan\n",
        "\n",
        "washed_price.fillna(method='bfill',axis=1)\n",
        "\n",
        "\n",
        "##计算分数\n",
        "point=pd.DataFrame(data=None, index=histroy_price.index, columns=['p1','p2','p3','p4','p5','p6','p_4year','fall','rise','total'])\n",
        "point['p1']=(washed_price['p2']-washed_price['p1'])/washed_price['p1']\n",
        "point['p2']=(washed_price['p3']-washed_price['p2'])/washed_price['p2']\n",
        "point['p3']=(washed_price['p4']-washed_price['p3'])/washed_price['p3']\n",
        "point['p4']=(washed_price['p5']-washed_price['p4'])/washed_price['p4']\n",
        "point['p5']=(washed_price['p6']-washed_price['p5'])/washed_price['p5']\n",
        "point['p6']=(washed_price['p7']-washed_price['p6'])/washed_price['p6']\n",
        "point['p_4year']=(washed_price['p7']-washed_price['p3'])/washed_price['p3']\n",
        "point['fall']=point['p2']+point['p4']\n",
        "point['rise']=point['p1']+point['p3']+point['p5']\n",
        "point['total']=point['fall']*3+point['rise']+point['p_4year']*5\n",
        "point.fillna(0);\n",
        "\n",
        "\n",
        "##查看分数\n",
        "show=point[point['fall']>-0.2].sort_values(by=['total'],ascending=False)\n",
        "show\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GumzcvZTHJtx"
      },
      "source": [
        "##结果分析\n",
        "##分析的思路是，抓取所有类型的基金在7个时间点的累计净值，这7个时间点构造了8个区间。参考指数，这八个区间大盘的涨跌趋势一致。着重关注在大盘上涨区间的盈利能力和在大盘回撤期间的风控能力，主要的指标都是区间收益率，对不同区间的收益率赋予不同的权值，即可计算出每一只基金的分数。\n",
        "\n",
        "##通过回撤比例，即可大致分开基金类型，例如，代码中选出大盘大回撤阶段累积收益率要高于-0.2，就选出了风控能力较好的基金，但是同样收益率也会下降。\n",
        "\n",
        "##分数选择出来之后最好在网上看看该基金的累计曲线，有些基金在某一时间点突然收益剧增，明显是偶然事件，虽然总分很高，但是并不具备普适性。\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}