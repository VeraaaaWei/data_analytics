{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9TcPj60r07aZ2K0J2eIZ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeraaaaWei/data_analytics/blob/Python/Fund%20data%20crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UODn7dOoCtnG"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import datetime\n",
        "import re\n",
        "import numpy as np\n",
        "import json\n",
        "from six import StringIO\n",
        "from six import BytesIO\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td9riV7lDUyj"
      },
      "source": [
        "##获取代理池，详见 https://github.com/1again/SmartProxyPool\n",
        "def get_proxy():\n",
        "    data_json = requests.get(\"http://proxy.1again.cc:35050/api/v1/proxy/?region=中国\").text\n",
        "    data = json.loads(data_json)\n",
        "    return data['data']['proxy']\n",
        "\n",
        "\n",
        "def get_url(url, params=None, proxies=None,header=None):\n",
        "    rsp = requests.get(url, params=params, proxies={\"http\": proxies},headers=header)    \n",
        "    rsp.raise_for_status()\n",
        "    return rsp.text\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uYNqqBkDifs"
      },
      "source": [
        "##获取全基金\n",
        "url = 'http://fund.eastmoney.com/js/fundcode_search.js'\n",
        "html = get_url(url,proxies=None)\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "exec('securities'+str(soup).strip('var '))\n",
        "funds = pd.DataFrame(data=securities, index=None, columns=['code','2','name','type','5'])\n",
        "# fund type类型 股票型-  混合型 债券型 指数型 保本型 理财型 货币型 混合-FOF ...\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urh3NzOgE6It"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxhvTXL3D6XJ"
      },
      "source": [
        "def get_header():\n",
        " # user_agent列表\n",
        "    user_agent_list = [\n",
        "  'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.71 Safari/537.1 LBBROWSER',\n",
        "  'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; QQDownload 732; .NET4.0C; .NET4.0E)',\n",
        "  'Mozilla/5.0 (Windows NT 5.1) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.84 Safari/535.11 SE 2.X MetaSr 1.0',\n",
        "  'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Maxthon/4.4.3.4000 Chrome/30.0.1599.101 Safari/537.36',\n",
        "  'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 UBrowser/4.0.3214.0 Safari/537.36'\n",
        "    ]\n",
        "# referer列表\n",
        "    referer_list = [\n",
        "  'http://fund.eastmoney.com/110022.html',\n",
        "  'http://fund.eastmoney.com/110023.html',\n",
        "  'http://fund.eastmoney.com/110024.html',\n",
        "  'http://fund.eastmoney.com/110025.html',\n",
        "  'https://www.baidu.com/s?wd=%E5%A4%A9%E5%A4%A9%E5%9F%BA%E9%87%91%E7%BD%91'\n",
        "    ]\n",
        "# 获取一个随机user_agent和Referer\n",
        "    header = {'User-Agent': random.choice(user_agent_list),'Referer': random.choice(referer_list)}\n",
        "    return header\n",
        "\n",
        "\n",
        "def get_fund_data(code, start='', end='',proxy_list=0):\n",
        "    url = 'http://fund.eastmoney.com/f10/F10DataApi.aspx'\n",
        "    params = {'type': 'lsjz', 'code': code, 'page': 1, 'per': 40, 'sdate': start, 'edate': end}\n",
        "    if proxy_list==0:\n",
        "        html = get_url(url,params,proxies=None,header=get_header())\n",
        "    else:\n",
        "        while(1):\n",
        "            try:\n",
        "                proxy_random=random.choice(proxy_list)\n",
        "                html = get_url(url,params,proxies=proxy_random,header=get_header())\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    records = pd.DataFrame(data=None, index=None, columns=['Code','NetAssetValue','AccumulatedNetValue','ChangePercent'])\n",
        "    tab = soup.findAll('tbody')[0]\n",
        "    for tr in tab.findAll('tr'):\n",
        "        if tr.findAll('td') and len((tr.findAll('td'))) == 7:\n",
        "            date=datetime.datetime.strptime(str(tr.select('td:nth-of-type(1)')[0].getText().strip()),'%Y-%m-%d')\n",
        "            if tr.select('td:nth-of-type(2)')[0].getText().strip()=='':\n",
        "                nav=0\n",
        "            else:\n",
        "                nav=float(tr.select('td:nth-of-type(2)')[0].getText().strip())\n",
        "\n",
        "            if tr.select('td:nth-of-type(3)')[0].getText().strip()=='':\n",
        "                aav=0\n",
        "            else:\n",
        "                aav=float(tr.select('td:nth-of-type(3)')[0].getText().strip()) \n",
        "\n",
        "            if tr.select('td:nth-of-type(4)')[0].getText().strip('%')=='':\n",
        "                cpt=0\n",
        "            else:\n",
        "                cpt=float(tr.select('td:nth-of-type(4)')[0].getText().strip('%'))\n",
        "            records.loc[date,:]=[code,nav,aav,cpt]\n",
        "            \n",
        "    reg=re.compile(r\"(?<=pages:)\\d+\")\n",
        "    match=reg.search(str(soup))\n",
        "    pages=int(match.group(0))\n",
        "    if pages >1:\n",
        "        for p in range (2,pages+1):\n",
        "            params = {'type': 'lsjz', 'code': code, 'page': p, 'per': 40, 'sdate': start, 'edate': end}\n",
        "            html = get_url(url, params)\n",
        "            soup = BeautifulSoup(html, 'html.parser')\n",
        "            tab = soup.findAll('tbody')[0]\n",
        "            for tr in tab.findAll('tr'):\n",
        "                if tr.findAll('td') and len((tr.findAll('td'))) == 7:\n",
        "                    date=datetime.datetime.strptime(str(tr.select('td:nth-of-type(1)')[0].getText().strip()),'%Y-%m-%d')\n",
        "                    if tr.select('td:nth-of-type(2)')[0].getText().strip()=='':\n",
        "                        nav=0\n",
        "                    else:\n",
        "                        nav=float(tr.select('td:nth-of-type(2)')[0].getText().strip())\n",
        "                    \n",
        "                    if tr.select('td:nth-of-type(3)')[0].getText().strip()=='':\n",
        "                        aav=0\n",
        "                    else:\n",
        "                        aav=float(tr.select('td:nth-of-type(3)')[0].getText().strip()) \n",
        "                    \n",
        "                    if tr.select('td:nth-of-type(4)')[0].getText().strip('%')=='':\n",
        "                        cpt=0\n",
        "                    else:\n",
        "                        cpt=float(tr.select('td:nth-of-type(4)')[0].getText().strip('%'))\n",
        "                        \n",
        "                    records.loc[date,:]=[code,nav,aav,cpt]    \n",
        "    return records\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 获取数据示例：get_fund_data('163402','2018-09-18','2019-09-18')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "eYMq6auDEvfC",
        "outputId": "f98f98da-5782-4ee6-eb08-f5337f46c503"
      },
      "source": [
        "\n",
        "get_fund_data('163402','2018-09-18','2019-09-18')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Code</th>\n",
              "      <th>NetAssetValue</th>\n",
              "      <th>AccumulatedNetValue</th>\n",
              "      <th>ChangePercent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-09-18</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.7928</td>\n",
              "      <td>9.659</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-17</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.7874</td>\n",
              "      <td>9.6374</td>\n",
              "      <td>-1.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-16</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.7969</td>\n",
              "      <td>9.6754</td>\n",
              "      <td>-0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-12</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.7981</td>\n",
              "      <td>9.6802</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-09-11</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.7911</td>\n",
              "      <td>9.6522</td>\n",
              "      <td>-0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-09-25</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.6421</td>\n",
              "      <td>9.0571</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-09-21</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.6453</td>\n",
              "      <td>9.0699</td>\n",
              "      <td>2.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-09-20</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.6325</td>\n",
              "      <td>9.0188</td>\n",
              "      <td>-0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-09-19</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.6343</td>\n",
              "      <td>9.026</td>\n",
              "      <td>1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-09-18</th>\n",
              "      <td>163402</td>\n",
              "      <td>0.8069</td>\n",
              "      <td>8.988</td>\n",
              "      <td>1.29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>245 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Code NetAssetValue AccumulatedNetValue ChangePercent\n",
              "2019-09-18  163402        0.7928               9.659          0.69\n",
              "2019-09-17  163402        0.7874              9.6374         -1.19\n",
              "2019-09-16  163402        0.7969              9.6754         -0.15\n",
              "2019-09-12  163402        0.7981              9.6802          0.88\n",
              "2019-09-11  163402        0.7911              9.6522         -0.49\n",
              "...            ...           ...                 ...           ...\n",
              "2018-09-25  163402        0.6421              9.0571          -0.5\n",
              "2018-09-21  163402        0.6453              9.0699          2.02\n",
              "2018-09-20  163402        0.6325              9.0188         -0.28\n",
              "2018-09-19  163402        0.6343               9.026          1.18\n",
              "2018-09-18  163402        0.8069               8.988          1.29\n",
              "\n",
              "[245 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}